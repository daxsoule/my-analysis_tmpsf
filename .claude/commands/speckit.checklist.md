---
description: Generate a reproducibility checklist for the analysis to verify it can be reproduced from raw data to final outputs.
---

## User Input

```text
$ARGUMENTS
```

Consider the user input before proceeding (if not empty). User may specify a focus area (e.g., "data only", "pre-submission").

## Goal

Generate a reproducibility checklist that validates whether the analysis can be reproduced by someone else (or yourself in 6 months). This is a gate check, typically run before sharing results or submitting for publication.

## Execution Steps

### 1. Setup

Run `.specify/scripts/bash/check-prerequisites.sh --json` from repo root and parse JSON for FEATURE_DIR.

### 2. Load Context

Read from FEATURE_DIR:
- `spec.md` - research questions, data sources, expected outputs
- `plan.md` - pipeline structure, environment, methods
- `tasks.md` - task completion status

Also load `.specify/memory/constitution.md` for project standards.

### 3. Generate Checklist

Create `FEATURE_DIR/reproducibility-checklist.md` with items covering:

**Data Accessibility**
- Are all raw data sources documented with access methods (URL, path, API)?
- Can someone outside the project obtain the same raw data?
- Are data access credentials/permissions documented (even if not shared)?
- Is data format and structure documented?

**Environment**
- Is the computational environment specified (language, version)?
- Are all dependencies listed with versions (requirements.txt, environment.yml)?
- Can the environment be recreated from the specification?
- Are any system-level dependencies documented?

**Code & Scripts**
- Are all scripts tracked in version control?
- Do scripts run without manual intervention?
- Are file paths relative or configurable (not hardcoded to one machine)?
- Is the execution order documented?

**Data Integrity**
- Is raw data preserved (never modified in place)?
- Do transformations produce new files rather than overwriting?
- Is missing/filtered data handling documented?
- Are intermediate files regenerable from raw data?

**Provenance**
- Can each output be traced to the code and data that produced it?
- Are key parameter choices documented?
- Are random seeds set and documented (if applicable)?
- Is the analysis date/version recorded?

**Outputs**
- Are all expected outputs (figures, tables) generated?
- Do outputs match the spec requirements?
- Can outputs be regenerated by running the pipeline?

**Documentation**
- Is there a README explaining how to reproduce the analysis?
- Are non-obvious decisions documented in research.md?
- Is the research question answered with traceable evidence?

### 4. Customize Based on Context

- If spec mentions stochastic methods → emphasize random seed documentation
- If large data → add items about data storage/access for large files
- If collaboration → add items about shared environment setup
- If constitution has specific standards → add items checking alignment

### 5. Format Checklist

Use this structure:

```markdown
# Reproducibility Checklist: [ANALYSIS NAME]

**Analysis**: `specs/[NNN-short-name]/`
**Generated**: [DATE]
**Purpose**: Verify this analysis can be reproduced from raw data to final outputs

## Data Accessibility

- [ ] CHK001 All raw data sources documented with access methods
- [ ] CHK002 Data can be obtained by someone outside the project
- [ ] CHK003 Data format and structure documented

## Environment

- [ ] CHK004 Language and version specified
- [ ] CHK005 All dependencies listed with versions
- [ ] CHK006 Environment can be recreated from specification

## Code & Execution

- [ ] CHK007 All scripts tracked in version control
- [ ] CHK008 Scripts run without manual intervention
- [ ] CHK009 Execution order documented (README or run script)

## Data Integrity

- [ ] CHK010 Raw data preserved (not modified in place)
- [ ] CHK011 Transformations produce new files
- [ ] CHK012 Missing data handling documented

## Provenance

- [ ] CHK013 Each output traceable to code and data inputs
- [ ] CHK014 Key parameter choices documented
- [ ] CHK015 Random seeds set (if applicable)

## Outputs

- [ ] CHK016 All expected outputs generated
- [ ] CHK017 Outputs regenerable by running pipeline

## Documentation

- [ ] CHK018 README explains how to reproduce
- [ ] CHK019 Research question answered with traceable evidence

---

**Pass criteria**: All items checked, or unchecked items have documented justification.
```

### 6. Report

Output:
- Path to generated checklist
- Number of items
- Suggested use: "Review before sharing results or submitting"

## Operating Principles

- **One checklist per analysis**: Creates/overwrites `reproducibility-checklist.md`
- **Practical items**: Every item should be verifiable by inspection
- **Constitution alignment**: Include items that verify constitution standards are met
- **Gate, not busywork**: This is a final check, not ongoing tracking

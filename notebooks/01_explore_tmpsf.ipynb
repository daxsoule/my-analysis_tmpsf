{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# ASHES TMPSF Timeseries Exploration\n\n**Spec**: `specs/001-ashes-tmpsf-timeseries/spec.md`\n\n**Research Question**: How does diffuse hydrothermal vent temperature vary as a function of time for the year 2018 at the ASHES vent field?\n\n**Data**: OOI TMPSF sensor (RS03ASHS-MJ03B-07-TMPSFA301) - NetCDF files, 24 thermistor channels\n\n**Output**: Daily average temperature timeseries for 2018"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": "# Setup: Import packages and define paths\nimport xarray as xr\nimport pandas as pd\nimport numpy as np\nimport hvplot.pandas\nimport hvplot.xarray\nfrom pathlib import Path\n\n# Data paths\nDATA_DIR = Path('/home/jovyan/ooi/kdata/RS03ASHS-MJ03B-07-TMPSFA301-streamed-tmpsf_sample')\nOUTPUT_DIR = Path('/home/jovyan/my_data/axial/axial_tmpsf')\nFIGURE_DIR = Path('../outputs/figures')\n\n# Analysis parameters - 2018 only\nSTART_DATE = '2018-01-01'\nEND_DATE = '2018-12-31'\n\nprint(f'Data directory: {DATA_DIR}')\nprint(f'Number of NetCDF files: {len(list(DATA_DIR.glob(\"*.nc\")))}')\nprint(f'Analysis period: {START_DATE} to {END_DATE}')"
  },
  {
   "cell_type": "code",
   "id": "qq2t4a65i9j",
   "source": "# Load Data: Open all NetCDF files with xarray\n# Using open_mfdataset for multi-file loading with lazy evaluation\n\n# Get list of NetCDF files\nnc_files = sorted(DATA_DIR.glob('*.nc'))\nprint(f'Found {len(nc_files)} NetCDF files')\n\n# Load all files - this uses lazy loading (dask) by default\n# combine='nested' and concat_dim='obs' to handle the OOI data structure\nprint('Loading dataset (lazy)...')\nds = xr.open_mfdataset(\n    nc_files,\n    combine='nested',\n    concat_dim='obs',\n    parallel=True\n)\n\n# Swap dims from 'obs' to 'time' for easier time-based operations\nds = ds.swap_dims({'obs': 'time'})\nprint(f'Dataset loaded: {ds.dims}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "qazb1yj3f1",
   "source": "# Select temperature variables and QC flags\n# Temperature channels: temperature01 through temperature24\n# QC flags: temperatureNN_qartod_results\n\ntemp_vars = [f'temperature{i:02d}' for i in range(1, 25)]\nqc_vars = [f'temperature{i:02d}_qartod_results' for i in range(1, 25)]\n\n# Check which variables exist in the dataset\navailable_temp = [v for v in temp_vars if v in ds.data_vars]\navailable_qc = [v for v in qc_vars if v in ds.data_vars]\n\nprint(f'Temperature variables found: {len(available_temp)}/24')\nprint(f'QC flag variables found: {len(available_qc)}/24')\n\n# Select only the variables we need (temperature + time + QC flags)\nvars_to_keep = ['time'] + available_temp + available_qc\nds_selected = ds[available_temp + available_qc]\nprint(f'Selected dataset variables: {len(ds_selected.data_vars)}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6in6gc8lx6s",
   "source": "# Filter to 2018\nprint(f'Original time range: {ds_selected.time.min().values} to {ds_selected.time.max().values}')\n\nds_filtered = ds_selected.sel(time=slice(START_DATE, END_DATE))\n\nprint(f'Filtered time range: {ds_filtered.time.min().values} to {ds_filtered.time.max().values}')\nprint(f'Number of observations: {ds_filtered.dims[\"time\"]}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9bewvqez8v",
   "source": "## QC: Data Loading Verification\n\nVerify that:\n1. Time range covers 2018\n2. All 24 temperature channels are present",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "7id0rid4c8r",
   "source": "# QC: Verify time range and temperature channels\n\n# T007: Check time range is 2018\ntime_min = pd.Timestamp(ds_filtered.time.min().values)\ntime_max = pd.Timestamp(ds_filtered.time.max().values)\nexpected_start = pd.Timestamp('2018-01-01')\nexpected_end = pd.Timestamp('2018-12-31')\n\nassert time_min.year == 2018, f'Time range does not start in 2018: {time_min}'\nassert time_max.year == 2018, f'Time range does not end in 2018: {time_max}'\nprint(f'✓ T007: Time range verified: {time_min.date()} to {time_max.date()}')\n\n# T008: Check all 24 temperature channels\nassert len(available_temp) == 24, f'Missing temperature channels: found {len(available_temp)}/24'\nprint(f'✓ T008: All 24 temperature channels present')\n\nprint('\\nPhase 2 checkpoint passed: Data loaded and filtered to 2018')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0xhzq119bamc",
   "source": "## Phase 3: QC Assessment\n\nExamine QARTOD flags and filter suspect data.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "sr5ysebn89",
   "source": "# Examine QARTOD flag distribution\n# QARTOD flags: 1=pass, 2=not evaluated, 3=suspect, 4=fail, 9=missing\n\nif available_qc:\n    # Check flag distribution for first temperature channel\n    qc_var = available_qc[0]\n    print(f'Examining QC flags for {qc_var}:')\n    \n    # Load a sample of QC flags\n    qc_sample = ds_filtered[qc_var].values\n    unique, counts = np.unique(qc_sample[~np.isnan(qc_sample)], return_counts=True)\n    \n    flag_meanings = {1: 'pass', 2: 'not evaluated', 3: 'suspect', 4: 'fail', 9: 'missing'}\n    for flag, count in zip(unique, counts):\n        pct = 100 * count / len(qc_sample)\n        meaning = flag_meanings.get(int(flag), 'unknown')\n        print(f'  Flag {int(flag)} ({meaning}): {count:,} ({pct:.1f}%)')\nelse:\n    print('No QARTOD QC flags found in dataset')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "q5mc0cciu9p",
   "source": "## Phase 4: DataFrame Creation & Daily Averaging\n\nConvert to pandas DataFrame and compute daily averages.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "cv0fj5mli",
   "source": "# Convert to pandas DataFrame\n# Select only temperature variables (exclude QC flags for now)\nprint('Converting to DataFrame...')\ndf = ds_filtered[available_temp].to_dataframe()\nprint(f'DataFrame shape: {df.shape}')\nprint(f'Columns: {list(df.columns)}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "z7no8txspyh",
   "source": "# Compute daily average temperature\n# Average across all 24 thermistor channels, then resample to daily\n\n# First compute mean across all temperature channels for each timestamp\ndf['temp_mean'] = df[available_temp].mean(axis=1)\n\n# Resample to daily averages\ndf_daily = df['temp_mean'].resample('D').mean().to_frame()\ndf_daily.columns = ['daily_avg_temp']\n\nprint(f'Daily averages shape: {df_daily.shape}')\nprint(f'Date range: {df_daily.index.min().date()} to {df_daily.index.max().date()}')\nprint(f'Number of days: {len(df_daily)}')\ndf_daily.head()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "tk73sskkp8n",
   "source": "# T017 QC: Verify daily averages DataFrame\n# 2018 has 365 days\n\nexpected_days = 365\nactual_days = len(df_daily)\n\nprint(f'Expected days: {expected_days}')\nprint(f'Actual days: {actual_days}')\n\nif actual_days == expected_days:\n    print(f'✓ T017: Daily averages has {actual_days} rows (full year)')\nelse:\n    missing = expected_days - actual_days\n    print(f'⚠ T017: Missing {missing} days ({actual_days}/{expected_days})')\n    \n# Check for NaN values\nnan_count = df_daily['daily_avg_temp'].isna().sum()\nprint(f'Days with NaN: {nan_count}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7oaerysyml2",
   "source": "## Phase 5: Visualization\n\nInteractive timeseries plot of daily average temperature for 2018.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "m9h25dqte0l",
   "source": "# Create interactive hvplot timeseries\nplot = df_daily.hvplot.line(\n    y='daily_avg_temp',\n    title='ASHES Vent Field - Daily Average Temperature (2018)',\n    xlabel='Date',\n    ylabel='Temperature (°C)',\n    width=900,\n    height=400,\n    grid=True\n)\nplot",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5be2eurskk",
   "source": "# T022 QC: Verify plot displays 2018 time range\nprint('Plot verification:')\nprint(f'  Start date: {df_daily.index.min().date()}')\nprint(f'  End date: {df_daily.index.max().date()}')\nprint(f'  Temperature range: {df_daily[\"daily_avg_temp\"].min():.2f}°C to {df_daily[\"daily_avg_temp\"].max():.2f}°C')\nprint(f'  Mean temperature: {df_daily[\"daily_avg_temp\"].mean():.2f}°C')\n\nif df_daily.index.min().year == 2018 and df_daily.index.max().year == 2018:\n    print('✓ T022: Plot displays 2018 time range')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ay3svd87i2m",
   "source": "# Optional: Save outputs\n# Uncomment to save DataFrame and plot\n\n# Save daily averages to parquet\n# OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n# df_daily.to_parquet(OUTPUT_DIR / 'tmpsf_2018_daily.parquet')\n# print(f'Saved DataFrame to {OUTPUT_DIR / \"tmpsf_2018_daily.parquet\"}')\n\n# Save plot to HTML\n# FIGURE_DIR.mkdir(parents=True, exist_ok=True)\n# hvplot.save(plot, FIGURE_DIR / 'tmpsf_2018_daily.html')\n# print(f'Saved plot to {FIGURE_DIR / \"tmpsf_2018_daily.html\"}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}